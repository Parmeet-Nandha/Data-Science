{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web Crawler(Professor List).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gA056KRfFuS"
      },
      "source": [
        "##Professor List Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5d7RZGhfXE2"
      },
      "source": [
        "###  Import and install web crawling library. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1ZsHADCfEH-",
        "outputId": "10c42361-a245-4bc3-c97d-8f36501a70f2"
      },
      "source": [
        "# write your import and necessary web crawling libary here\n",
        "# install chromium, its driver, and selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium\n",
        "# set options to be headless, ..\n",
        "from selenium import webdriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "# open it, go to a website, and get results\n",
        "wd = webdriver.Chrome('chromedriver',options=options)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 14.2 kB/88.7\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to cloud.r-pr\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\r                                                                               \rHit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\r                                                                               \rIgn:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\r                                                                               \rHit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,185 kB]\n",
            "Hit:11 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,415 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,619 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,185 kB]\n",
            "Fetched 8,655 kB in 3s (2,755 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 86.0 MB of archives.\n",
            "After this operation, 298 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 91.0.4472.101-0ubuntu0.18.04.1 [1,124 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 91.0.4472.101-0ubuntu0.18.04.1 [76.1 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 91.0.4472.101-0ubuntu0.18.04.1 [3,937 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 91.0.4472.101-0ubuntu0.18.04.1 [4,837 kB]\n",
            "Fetched 86.0 MB in 4s (23.3 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_91.0.4472.101-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_91.0.4472.101-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_91.0.4472.101-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_91.0.4472.101-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8HJSfwkgrwW"
      },
      "source": [
        "###  Find all professors in School of IT and save it as csv. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xstq9qQBgwVs"
      },
      "source": [
        "# here we first define the parsing method, you will need to use this parsing method to format the professor full name and title from the staff page.\n",
        "# the name of the professor from staff page will be split by space and last two words are full name \n",
        "def parse_name(stringtext):\n",
        "  return \" \".join(stringtext.split(\" \")[-2:]),\" \".join(stringtext.split(\" \")[:-2])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL5vBzxsg0As"
      },
      "source": [
        "import pandas as pd\n",
        "# the crawling information will be stored in pandas dataframe and then save as csv\n",
        "# below you are required to use the parse_name method to crawl the professor's full name and title\n",
        "# The column name must be same as the provided professor-list.csv\n",
        "\n",
        "wd.get(\"https://www.deakin.edu.au/information-technology/staff-listing\")\n",
        "shapes = wd.find_elements_by_tag_name('table')\n",
        "data = []\n",
        "for table in shapes[:3]:\n",
        "  for tr in table.find_elements_by_tag_name('tr'):\n",
        "    #tds = tr.find_elements_by_tag_name('td')\n",
        "    for td in tr.find_elements_by_tag_name('td'):\n",
        "        for a in td.find_elements_by_tag_name('a'):\n",
        "          data.append(parse_name(a.get_attribute('text')))\n",
        "df = pd.DataFrame(data)\n",
        "df['University'] = 'Deakin University'\n",
        "df.columns = ['Name','Title','University']\n",
        "df.to_csv('Professor_name_list.csv', )"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJdF__J3e3Gz"
      },
      "source": [
        "##  Professor Citation Information Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCd5_S0Yeujl"
      },
      "source": [
        "# search the google scholar for all professors to obtain their citations_all, h-index_all, i10_all, citation_since2016\n",
        "# h-index-2016 and i10_since2016. Save the results as csv and must having all the professors name, title and all 6 citation information.\n",
        "# if the professors did not have the google scholar profle with the name, save the 6 citation information as string \"na\"\n",
        "# you are requests to use loops and Conditional Statements to finish this task (eg: while / for, if...), failed to use loop\n",
        "# and conditional statements will occur 0 mark.\n",
        "# hint: sometimes, to render the google scholar page, you need to wait for the brower for few seconds, you could use \"from time import sleep\"\n",
        "# to have sleep(5) as the wait action for waiting 5 seconds.  \n",
        "# The column name must be same as the provided professor-citation-information.csv \n",
        "# write your code for this part as below:\n",
        "\n",
        "\n",
        "from time import sleep\n",
        "def fetch_google_scholar_profile(input):\n",
        "  statistics = []\n",
        "  url = str(\"https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=\"+input+\"&btnG=\")\n",
        "  wd.get(url)\n",
        "  #sleep(5)\n",
        "  bodyText = wd.find_element_by_tag_name(\"body\").text\n",
        "  if \"didn't match any user profiles\" in bodyText:\n",
        "    statistics.extend(['na', 'na', 'na','na','na','na'])\n",
        "  else:\n",
        "    elems = wd.find_element_by_class_name(\"gs_ai_pho\")\n",
        "    profile_url = elems.get_attribute(\"href\")\n",
        "    wd.get(profile_url)\n",
        "    table = wd.find_element_by_id(\"gsc_rsb_st\")\n",
        "    for td in table.find_elements_by_class_name('gsc_rsb_std'):\n",
        "      #for td in tr.find_elements_by_tag_name('td'):\n",
        "      #  a = td.find_element_by_tag_name('a')\n",
        "      #tds = tr.find_elements_by_class_name('gsc_rsb_std')\n",
        "      statistics.append(td.get_attribute('textContent'))\n",
        "  return statistics"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMGxLAt8exPy"
      },
      "source": [
        "## Get list of Professors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10XMC4qrez_x",
        "outputId": "fc48a1e2-9f99-4767-8ad1-6c587e801a5f"
      },
      "source": [
        "citation_info = []\n",
        "for i in range(len(df.Name)):\n",
        "  author = df.Name[i].split(\" \",1)[0]+\"+\"+df.Name[i].split(\" \",1)[1]+\"+deakin+\"+\"university\"\n",
        "  print(author)\n",
        "  citation = fetch_google_scholar_profile(author)\n",
        "  citation.insert(0, df.Title[i])\n",
        "  citation.insert(0, df.Name[i])\n",
        "  citation_info.append(citation)\n",
        "  print('finished')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lynn+Batten+deakin+university\n",
            "finished\n",
            "Andrzej+Goscinski+deakin+university\n",
            "finished\n",
            "Jemal+Abawajy+deakin+university\n",
            "finished\n",
            "Maia+Angelova+deakin+university\n",
            "finished\n",
            "Gleb+Beliakov+deakin+university\n",
            "finished\n",
            "Terry+Caelli+deakin+university\n",
            "finished\n",
            "Jinho+Choi+deakin+university\n",
            "finished\n",
            "Chang-Tsun+Li+deakin+university\n",
            "finished\n",
            "Robin+Doss+deakin+university\n",
            "finished\n",
            "Peter+Eklund+deakin+university\n",
            "finished\n",
            "Seng+Loke+deakin+university\n",
            "finished\n",
            "Antonio+Robles-Kelly+deakin+university\n",
            "finished\n",
            "Jean-Guy+Schneider+deakin+university\n",
            "finished\n",
            "Yong+Xiang+deakin+university\n",
            "finished\n",
            "John+Yearwood+deakin+university\n",
            "finished\n",
            "Arkady+Zaslavsky+deakin+university\n",
            "finished\n",
            "Mohamed+Abdelrazek+deakin+university\n",
            "finished\n",
            "Andrew+Cain+deakin+university\n",
            "finished\n",
            "Richard+Dazeley+deakin+university\n",
            "finished\n",
            "Guangyan+Huang+deakin+university\n",
            "finished\n",
            "Gang+Li+deakin+university\n",
            "finished\n",
            "Jianxin+Li+deakin+university\n",
            "finished\n",
            "Xiao+Liu+deakin+university\n",
            "finished\n",
            "Vicky+Mak+deakin+university\n",
            "finished\n",
            "Tim+Wilkin+deakin+university\n",
            "finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR77cggjhA09"
      },
      "source": [
        "Import professor List to CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7cRR1w3hFY6"
      },
      "source": [
        "import numpy as np\n",
        "df_citation = pd.DataFrame(np.array(citation_info))\n",
        "df_citation.columns = ['Name','Title','citation_all','citation_since2016','h-index_all','h-index_since2016','i10-index_all','i10-index_since2016']\n",
        "df_citation.to_csv('Professor_citation_informaton.csv', )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXWKbd9XerxO"
      },
      "source": [
        "### Find out the professor name having the most citations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6f-zmq9fhRqg",
        "outputId": "137149e3-161a-4c86-d4aa-8daec278ee5c"
      },
      "source": [
        "#replace na values with 0(data cleaning)\n",
        "df_citation = df_citation.replace('na','0')\n",
        "\n",
        "#get index with max value\n",
        "index_max = df_citation.citation_all.astype('float').argmax()\n",
        "# retreiev name of professor with max citiations\n",
        "df_citation.Name[index_max]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Arkady Zaslavsky'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icO-6Z8GhjRW"
      },
      "source": [
        "### 4.3 Find out the row for associate professor having the most i10-index "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u60nEc03hnaz",
        "outputId": "3e4b642e-b493-466f-c299-9fefd2c23d8c"
      },
      "source": [
        "# find out the row for associate professor having the most i10_index since 2016 (please remove those professor who does not have google scholar page)\n",
        "filter_index = df_citation[df_citation.Title == 'Associate Professor']\n",
        "index_max = filter_index['i10-index_since2016'].astype('float').argmax()\n",
        "filter_index.iloc[4]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Name                               Gang Li\n",
              "Title                  Associate Professor\n",
              "citation_all                          4292\n",
              "citation_since2016                    3000\n",
              "h-index_all                             28\n",
              "h-index_since2016                       25\n",
              "i10-index_all                           93\n",
              "i10-index_since2016                     68\n",
              "Name: 20, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmEeJgXvhxe-"
      },
      "source": [
        "### Find out all the professors name who has the citations_since2016 > 2500"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mk6NjiJ3h0x-",
        "outputId": "2006a25d-0a6f-4ab0-bc6f-8a2d02276c1b"
      },
      "source": [
        "# find out all the professors name who has the citations_since2016 > 2500\n",
        "df_citation.Name[df_citation['citation_since2016'].astype('float') > 2500]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4        Gleb Beliakov\n",
              "6           Jinho Choi\n",
              "10           Seng Loke\n",
              "13          Yong Xiang\n",
              "15    Arkady Zaslavsky\n",
              "20             Gang Li\n",
              "Name: Name, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}